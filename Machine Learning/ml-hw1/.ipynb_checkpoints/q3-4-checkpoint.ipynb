{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Implement maximum likelihood classification in python. Input to your program is CSV\n",
    "file, with last attribute assumed to class label. You can assume all non-class attributes\n",
    "are continuous random variables. It should take two input files, training file for\n",
    "constructing model and test file to estimate various accuracy measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv').values\n",
    "np.random.shuffle(iris)\n",
    "train, test = train_test_split(iris, test_size = 0.5)\n",
    "vals = train[:,:-1].astype('float')\n",
    "labels = np.unique(train[:, -1])\n",
    "num_observations = len(train)\n",
    "num_labels = len(vals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each x value, calculate g(x) per label, and select the label with highest g(x) value\n",
    "\n",
    "# get respective means and cov matrices per label\n",
    "def get_label_stats(vals, labels):\n",
    "    label_stats = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_stats[label] = {}\n",
    "        # apply boolean mask\n",
    "        label_data = vals[vals[:, -1] == label]\n",
    "        # remove label column\n",
    "        label_data = label_data[:,:-1].astype('float')\n",
    "        num_samples = len(label_data)\n",
    "        label_stats[label]['mean'] = label_data.mean(axis = 0)\n",
    "        label_stats[label]['cov'] = np.asmatrix(np.cov(label_data.T))\n",
    "        label_stats[label]['probability'] = float(num_samples/num_observations)\n",
    "\n",
    "    return label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify each x value by selecting the max g(x) value from each label\n",
    "# label(x) = max(g(x, label1), g(x, label2), ..., g(x, labeln))\n",
    "def ml_classifier(label_stats, vals):\n",
    "    classifier_label = []\n",
    "    for x in vals:\n",
    "        # calculate g(x) per label\n",
    "        curr_label = None\n",
    "        prev_g_x = 0.0\n",
    "        max_g_x = 0.0\n",
    "        for label in label_stats:\n",
    "            stats = label_stats[label]\n",
    "            mean = stats['mean']\n",
    "            cov = stats['cov']\n",
    "            prob = stats['probability']\n",
    "            g_x = -0.5 * ((x - mean).T @ np.linalg.inv(cov) @ (x - mean))\n",
    "            constant = np.log(prob) - (len(vals[0])/2)\n",
    "            if curr_label is None:\n",
    "                curr_label = label            \n",
    "                max_g_x = g_x\n",
    "                prev_g_x = g_x\n",
    "            else:\n",
    "                prev_g_x = max_g_x\n",
    "                max_g_x = max(max_g_x, g_x)\n",
    "                if max_g_x != prev_g_x:\n",
    "                    curr_label = label\n",
    "        classifier_label.append(curr_label)\n",
    "    classifier_label = np.array(classifier_label)\n",
    "    return classifier_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Counts\n",
      "unique:  ['setosa' 'versicolor' 'virginica']\n",
      "counts:  [16 30 29]\n",
      "Actual Counts\n",
      "unique:  ['setosa' 'versicolor' 'virginica']\n",
      "counts:  [16 31 28]\n",
      "Classifier Accuracy:  98.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "label_stats = get_label_stats(train, labels)\n",
    "classifier_label = ml_classifier(label_stats, vals)\n",
    "print(\"Classifier Counts\")\n",
    "unique, classifier_counts = np.unique(classifier_label, return_counts = True)\n",
    "print(\"unique: \", unique)\n",
    "print(\"counts: \", classifier_counts)\n",
    "print(\"Actual Counts\")\n",
    "unique, actual_counts = np.unique(train[:, -1], return_counts = True)\n",
    "print(\"unique: \", unique)\n",
    "print(\"counts: \", actual_counts)\n",
    "difference = 0\n",
    "for i in range(len(classifier_counts)):\n",
    "    if classifier_counts[i] - actual_counts[i] < 0:\n",
    "        difference += (classifier_counts[i] - actual_counts[i])\n",
    "print(\"Classifier Accuracy: \", float((sum(classifier_counts) + difference) / sum(classifier_counts)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classifier on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = test[:,:-1].astype('float')\n",
    "labels = np.unique(test[:, -1])\n",
    "num_observations = len(test)\n",
    "num_labels = len(vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Counts\n",
      "unique:  ['setosa' 'versicolor' 'virginica']\n",
      "counts:  [16 30 29]\n",
      "Actual Counts\n",
      "unique:  ['setosa' 'versicolor' 'virginica']\n",
      "counts:  [16 31 28]\n",
      "Classifier Accuracy:  98.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "label_stats = get_label_stats(test, labels)\n",
    "classifier_counts = ml_classifier(label_stats, vals)\n",
    "print(\"Classifier Counts\")\n",
    "unique, classifier_counts = np.unique(classifier_label, return_counts = True)\n",
    "print(\"unique: \", unique)\n",
    "print(\"counts: \", classifier_counts)\n",
    "print(\"Actual Counts\")\n",
    "unique, actual_counts = np.unique(train[:, -1], return_counts = True)\n",
    "print(\"unique: \", unique)\n",
    "print(\"counts: \", actual_counts)\n",
    "difference = 0\n",
    "for i in range(len(classifier_counts)):\n",
    "    if classifier_counts[i] - actual_counts[i] < 0:\n",
    "        difference += (classifier_counts[i] - actual_counts[i])\n",
    "print(\"Classifier Accuracy: \", float((sum(classifier_counts) + difference) / sum(classifier_counts)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Implement entropy and gain functions. For a given data (CSV file, last attribute is class\n",
    "label), output entropy and gain values for each attribute, and determine root node\n",
    "attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p != 0:\n",
    "        return -p*np.log2(p)  \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of sepal_length : 1.0689219720135832\n",
      "Entropy of sepal_width : 1.336296325775044\n",
      "Entropy of petal_length : 0.9182958340544897\n",
      "Entropy of petal_width : 0.8915883594258673\n"
     ]
    }
   ],
   "source": [
    "column_entropies = {}   \n",
    "iris = pd.read_csv('iris.csv')   \n",
    "for col in iris.columns:\n",
    "    if col != iris.columns[-1]:\n",
    "        greater_median = []\n",
    "        less_median= []\n",
    "        for i, row in iris.iterrows():\n",
    "            median = iris[col].median()\n",
    "            if row[col] >= median :\n",
    "                greater_median.append([row[col], row[iris.columns[-1]]])\n",
    "            else:\n",
    "                less_median.append([row[col], row[iris.columns[-1]]])\n",
    "\n",
    "        labels = [col, iris.columns[-1]]\n",
    "        greater_median = pd.DataFrame(greater_median, columns=labels)\n",
    "        less_median = pd.DataFrame(less_median, columns=labels)\n",
    "        class_1 = greater_median.groupby(iris.columns[-1]).count()[col].tolist()\n",
    "        class_2 = less_median.groupby(iris.columns[-1]).count()[col].tolist()\n",
    "        \n",
    "        class_1_entropy = sum([entropy(val / sum(class_1)) for val in class_1])\n",
    "        class_2_entropy = sum([entropy(val / sum(class_2)) for val in class_2])            \n",
    "        column_entropy = ((sum(class_1) * class_1_entropy) + (sum(class_2) * class_2_entropy))/(sum(class_1)+sum(class_2))\n",
    "        \n",
    "        print(\"Entropy of\", col,\":\", column_entropy )\n",
    "        column_entropies[col] = column_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain for sepal_length : 0.5160405287075729\n",
      "Gain for sepal_width : 0.2486661749461121\n",
      "Gain for petal_length : 0.6666666666666664\n",
      "Gain for petal_width : 0.6933741412952887\n"
     ]
    }
   ],
   "source": [
    "groups = iris.groupby(iris.columns[-1]).size().tolist()\n",
    "parent_entropy = sum([entropy(val / sum(groups)) for val in groups])\n",
    "column_gains = {}\n",
    "for col in iris.columns:\n",
    "    if col != iris.columns[-1]:\n",
    "        column_gains[col] = parent_entropy - column_entropies[col]\n",
    "        print(\"Gain for\", col, \":\", parent_entropy - column_entropies[col] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Node:  petal_width with optimal split of gain:  0.6933741412952887\n"
     ]
    }
   ],
   "source": [
    "root_node = max(column_gains, key = column_gains.get)\n",
    "print(\"Root Node: \", root_node, \"with optimal split of gain: \", column_gains[root_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
